{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/viniciusdutra314/faster-whisper-youtube-jellyfin/blob/main/faster_whisper_youtube.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96kvih9mXkNN"
      },
      "source": [
        "# **Youtube Videos Transcription with Faster Whisper + Jellyfin support**\n",
        "\n",
        "\n",
        "[![repository shield](https://img.shields.io/static/v1?label=&message=Repository&color=blue&style=for-the-badge&logo=github&link=https://github.com/lewangdev/faster_whisper_youtube)](https://github.com/viniciusdutra314/faster-whisper-youtube-jellyfin)\n",
        "\n",
        "This is a notebook where you can download videos/playlists from YouTube and transcribe them quickly using Faster Whisper. The videos and subtitles will be saved on your Google Drive in a Jellyfin-friendly format, ready to be used with the [Youtube-Metadata-Plugin](https://github.com/ankenyr/jellyfin-youtube-metadata-plugin).\n",
        "\n",
        "Credits:\n",
        "This is a fork from [lewangdev](https://github.com/lewangdev/faster-whisper-youtube) which itself is a fork of [ArthurFDLR](https://github.com/ArthurFDLR/whisper-youtube), i just added a few lines to make it compatible with jellyfin, thank you guys to have made this so simple yet extremly useful google colab notebook!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "jz8CbpHhyVkI"
      },
      "outputs": [],
      "source": [
        "#@markdown # **Jellyfin** <img src=\"https://jellyfin.org/images/logo.svg\"> { display-mode: \"form\" }\n",
        "\n",
        "user=\"\" #@param {type:\"string\"}\n",
        "#@markdown Video or playlist link:\n",
        "URL=\"\" #@param {type:\"string\"}\n",
        "drive_path = \"Faster-Whisper-YT-Jellyfin\" #@param {type:\"string\"}\n",
        "save_dir=f\"/content/drive/MyDrive/Faster-Whisper-YT-Jellyfin/{user}/\"\n",
        "from pathlib import Path\n",
        "from google.colab import drive\n",
        "drive_mount_path = Path(\"/\") / \"content\" / \"drive\"\n",
        "drive.mount(str(drive_mount_path))\n",
        "drive_mount_path /= \"My Drive\"\n",
        "drive_whisper_path = drive_mount_path / Path(drive_path.lstrip(\"/\"))\n",
        "drive_whisper_path.mkdir(parents=True, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "xYLPZQX9S7tU"
      },
      "outputs": [],
      "source": [
        "#@markdown # **Download Video/Playlist** ðŸ“º { display-mode: \"form\" }\n",
        "\n",
        "\n",
        "def seconds_to_time_format(s):\n",
        "    hours = s // 3600\n",
        "    s %= 3600\n",
        "    minutes = s // 60\n",
        "    s %= 60\n",
        "    seconds = s // 1\n",
        "    milliseconds = round((s % 1) * 1000)\n",
        "    return f\"{int(hours):02d}:{int(minutes):02d}:{int(seconds):02d},{int(milliseconds):03d}\"\n",
        "\n",
        "print(\"Downloading yt-dlp\")\n",
        "\n",
        "!pip install yt-dlp --quiet\n",
        "\n",
        "\n",
        "import sys\n",
        "import warnings\n",
        "import yt_dlp\n",
        "import subprocess\n",
        "import torch\n",
        "import shutil\n",
        "import numpy as np\n",
        "from IPython.display import display, Markdown, YouTubeVideo\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import subprocess\n",
        "command = [\"yt-dlp\", \"-o\", f\"{save_dir}[%(id)s].%(ext)s\", URL, \"--write-info-json\",\"--quiet\"]\n",
        "process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
        "for line in process.stdout:\n",
        "    print(line, end='')\n",
        "\n",
        "ydl_opts = {\n",
        "    'format': 'm4a/bestaudio/best',\n",
        "    'outtmpl': '%(id)s.%(ext)s',\n",
        "    'postprocessors': [{\n",
        "        'key': 'FFmpegExtractAudio',\n",
        "        'preferredcodec': 'wav',\n",
        "    }]\n",
        "}\n",
        "\n",
        "with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "    error_code = ydl.download([URL])\n",
        "    download_info = [ydl.extract_info(URL, download=False)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Ad6n1m4deAHp"
      },
      "outputs": [],
      "source": [
        "# @title **Run the model** ðŸš€ { display-mode: \"form\" }\n",
        "#@markdown Run this cell to execute the transcription of the video. This can take a while and very based on the length of the video and the number of parameters of the model selected above.\n",
        "#@markdown **The default options should be fine for most users**\n",
        "\n",
        "language = \"auto\" #@param {type:\"string\"}\n",
        "model_size = 'large-v2' #@param {type:\"string\"} ['tiny', 'tiny.en', 'base', 'base.en', 'small', 'small.en', 'medium', 'medium.en', 'large-v1', 'large-v2']\n",
        "device_type = \"cuda\" #@param {type:\"string\"} [\"cuda\",\"cpu\"]\n",
        "compute_type = \"float16\"\n",
        "word_level_timestamps = False #@param {type:\"boolean\"}\n",
        "#@markdown ---\n",
        "\n",
        "vad_filter = True\n",
        "vad_filter_min_silence_duration_ms = 50\n",
        "\n",
        "!pip install faster-whisper --quiet\n",
        "print(f\"Downloading {model_size} model\")\n",
        "from faster_whisper import WhisperModel\n",
        "model = WhisperModel(model_size,device=device_type,compute_type=compute_type)\n",
        "\n",
        "if \"entries\" in download_info[0]:\n",
        "  videos=download_info[0][\"entries\"]\n",
        "else:\n",
        "  videos=download_info\n",
        "\n",
        "\n",
        "for index,video_info in enumerate(videos):\n",
        "  print(f\"{index} of {len(videos)}\")\n",
        "  video_path_local=Path(f\"{video_info['id']}.wav\")\n",
        "\n",
        "  segments, info = model.transcribe(f\"{str(video_path_local)}\", beam_size=5,\n",
        "                                    language=None if language == \"auto\" else language,\n",
        "                                    word_timestamps=word_level_timestamps,\n",
        "                                    vad_filter=vad_filter,\n",
        "                                    vad_parameters=dict(min_silence_duration_ms=vad_filter_min_silence_duration_ms))\n",
        "\n",
        "  display(Markdown(f\"Detected language '{info.language}' with probability {info.language_probability}\"))\n",
        "\n",
        "  ext_name =\".srt\"\n",
        "  transcript_file_name = f\"{save_dir}[{video_path_local.stem}].srt\"\n",
        "  sentence_idx = 1\n",
        "  with open(transcript_file_name, 'w') as f:\n",
        "    for segment in segments:\n",
        "      if word_level_timestamps:\n",
        "        for word in segment.words:\n",
        "          ts_start = seconds_to_time_format(word.start)\n",
        "          ts_end = seconds_to_time_format(word.end)\n",
        "          print(f\"[{ts_start} --> {ts_end}] {word.word}\")\n",
        "          f.write(f\"{sentence_idx}\\n\")\n",
        "          f.write(f\"{ts_start} --> {ts_end}\\n\")\n",
        "          f.write(f\"{word.word}\\n\\n\")\n",
        "          f.write(\"\\n\")\n",
        "          sentence_idx = sentence_idx + 1\n",
        "      else:\n",
        "        ts_start = seconds_to_time_format(segment.start)\n",
        "        ts_end = seconds_to_time_format(segment.end)\n",
        "        print(f\"[{ts_start} --> {ts_end}] {segment.text}\")\n",
        "        f.write(f\"{sentence_idx}\\n\")\n",
        "        f.write(f\"{ts_start} --> {ts_end}\\n\")\n",
        "        f.write(f\"{segment.text.strip()}\\n\\n\")\n",
        "        sentence_idx = sentence_idx + 1\n",
        "\n",
        "  try:\n",
        "    shutil.copy(video_path_local.parent / transcript_file_name,\n",
        "              drive_whisper_path / transcript_file_name\n",
        "    )\n",
        "    display(Markdown(f\"**Transcript file created: {drive_whisper_path / transcript_file_name}**\"))\n",
        "  except:\n",
        "    display(Markdown(f\"**Transcript file created: {video_path_local.parent / transcript_file_name}**\"))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
